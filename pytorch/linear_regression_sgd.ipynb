{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "colored-forth",
   "metadata": {},
   "source": [
    "# Linear Regression from First Principles\n",
    "\n",
    "Exploring how one of the most basic machine learning models can be implemented using PyTorch and Stochastic Gradient Descent (SGD), from first principles. We then explore the same model using the PyTorch optimiser."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identical-victim",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ruled-verification",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence, Tuple\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mediterranean-disaster",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "mature-skill",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fde4fb7d270>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lightweight-soundtrack",
   "metadata": {},
   "source": [
    "## Simple Linear Regression from First Principles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impossible-chassis",
   "metadata": {},
   "source": [
    "Start by creating a dataset and dataloader for the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "romantic-photograph",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples = 400\n",
      "data[0] = (tensor([-2.]), tensor([-3.5256]))\n",
      "mini_batch[0] = [tensor([[-2.0000],\n",
      "        [-1.9900],\n",
      "        [-1.9800],\n",
      "        [-1.9700],\n",
      "        [-1.9600]]), tensor([[-3.5256],\n",
      "        [-2.7402],\n",
      "        [-2.6340],\n",
      "        [-3.5795],\n",
      "        [-2.0602]])]\n"
     ]
    }
   ],
   "source": [
    "class LinearModelData(Dataset):\n",
    "    \n",
    "    def __init__(self, b: float, w: float):\n",
    "        self.w = torch.tensor(w)\n",
    "        self.b = torch.tensor(b)\n",
    "        self.X = torch.arange(-2, 2, 0.01).view(-1, 1)\n",
    "        self.y = self.b + self.w * self.X + torch.randn(self.X.size())\n",
    "        self.len = self.y.shape[0]\n",
    "        \n",
    "    def __getitem__(self, idx: float) -> Tuple[torch.FloatTensor, torch.FloatTensor]:\n",
    "        return (self.X[idx], self.y[idx])\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return self.len\n",
    "    \n",
    "    \n",
    "data = LinearModelData(b=0, w=1)\n",
    "print(f'n_samples = {len(data)}')\n",
    "print(f'data[0] = {data[0]}')\n",
    "\n",
    "data_loader = DataLoader(dataset=data, batch_size=5)\n",
    "data_batches = list(data_loader)\n",
    "print(f'mini_batch[0] = {data_batches[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chief-irrigation",
   "metadata": {},
   "source": [
    "Now define the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "loaded-cycling",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(torch.nn.Module):\n",
    "    \"\"\"Linear regression from first principles using gradient descent.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.b = torch.nn.Parameter(torch.tensor([torch.randn(1)], requires_grad=True))\n",
    "        self.w = torch.nn.Parameter(torch.tensor([torch.randn(1)], requires_grad=True))\n",
    "        \n",
    "    def forward(self, x: torch.FloatTensor) -> torch.FloatTensor:\n",
    "        \"\"\"Compute a prediction.\"\"\"\n",
    "        y_hat = self.b + self.w * x\n",
    "        return y_hat\n",
    "    \n",
    "    def loss(self, y_hat: torch.FloatTensor, y: torch.FloatTensor):\n",
    "        \"\"\"Compute mean squared-error loss.\"\"\"\n",
    "        return torch.mean((y_hat - y) ** 2)\n",
    "    \n",
    "    def fit(\n",
    "        self,\n",
    "        data_loader: DataLoader,\n",
    "        n_epochs: int,\n",
    "        learning_rate: float\n",
    "    ) -> Sequence[float]:\n",
    "        \"\"\"Train the model over multiple epochs recording the loss for each.\"\"\"\n",
    "        \n",
    "        def process_batch(X: torch.FloatTensor, y: torch.FloatTensor) -> float:\n",
    "            y_hat = self.forward(X)\n",
    "            loss = self.loss(y_hat, y)\n",
    "            loss.backward()\n",
    "            \n",
    "            self.w.data -= lr * self.w.grad.data\n",
    "            self.w.grad.data.zero_()\n",
    "            \n",
    "            self.b.data -= lr * self.b.grad.data\n",
    "            self.b.grad.data.zero_()\n",
    "            \n",
    "            return loss.detach().numpy().tolist()\n",
    "            \n",
    "        def process_epoch() -> float:\n",
    "            return [process_batch(X, y) for X, y in data_loader][-1]\n",
    "            \n",
    "        lr = torch.tensor(learning_rate)\n",
    "        training_run = [process_epoch() for epoch in range(n_epochs)]\n",
    "        return training_run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunset-relief",
   "metadata": {},
   "source": [
    "Train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "welcome-headline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial parameters:\n",
      "  b: tensor([0.5864])\n",
      "  w: tensor([0.0956])\n",
      "\n",
      "post-training parameters:\n",
      "  b: tensor([0.0854])\n",
      "  w: tensor([0.8475])\n",
      "\n",
      "loss per-epoch:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5875463485717773,\n",
       " 1.5779364109039307,\n",
       " 1.5811569690704346,\n",
       " 1.580075740814209,\n",
       " 1.580438494682312,\n",
       " 1.5803169012069702,\n",
       " 1.5803571939468384,\n",
       " 1.5803438425064087,\n",
       " 1.580348253250122,\n",
       " 1.5803468227386475,\n",
       " 1.5803474187850952,\n",
       " 1.5803474187850952,\n",
       " 1.5803468227386475,\n",
       " 1.5803468227386475,\n",
       " 1.5803474187850952]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg = LinearRegression()\n",
    "print('initial parameters:')\n",
    "for k, v in lin_reg.state_dict().items():\n",
    "    print(f'  {k}: {v}')\n",
    "\n",
    "print('\\npost-training parameters:')\n",
    "per_epoch_loss = lin_reg.fit(data_loader, n_epochs=15, learning_rate=0.05)\n",
    "for k, v in lin_reg.state_dict().items():\n",
    "    print(f'  {k}: {v}')\n",
    "\n",
    "print('\\nloss per-epoch:')\n",
    "per_epoch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electrical-intent",
   "metadata": {},
   "source": [
    "Testing the model on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "prostate-indiana",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0649, grad_fn=<SqrtBackward>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = LinearModelData(b=0, w=1)\n",
    "rmse = torch.sqrt(torch.mean((lin_reg.forward(test_data.X) - test_data.y) ** 2))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrow-ownership",
   "metadata": {},
   "source": [
    "Which is in-line what one would expect with a noise term that is a standard Normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superior-lafayette",
   "metadata": {},
   "source": [
    "## Simple Linear Regression with the PyTorch Optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "southeast-priest",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionPyTorch(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size: int, output_size: int):\n",
    "        super(LinearRegressionPyTorch, self).__init__()\n",
    "        self.linear = torch.nn.Linear(input_size, output_size)\n",
    "        self.loss = torch.nn.MSELoss()  # this is a callable\n",
    "\n",
    "    def forward(self, X) -> torch.FloatTensor:\n",
    "        \"\"\"Compute a prediction.\"\"\"\n",
    "        return self.linear(X)\n",
    "    \n",
    "    def fit(\n",
    "        self,\n",
    "        data_loader: DataLoader,\n",
    "        n_epochs: int,\n",
    "        learning_rate: float\n",
    "    ) -> Sequence[float]:\n",
    "        \"\"\"Train the model over multiple epochs recording the loss for each.\"\"\"\n",
    "\n",
    "        def process_batch(X: torch.FloatTensor, y: torch.FloatTensor) -> float:\n",
    "            y_hat = self.forward(X)\n",
    "            loss = self.loss(y_hat, y)\n",
    "            optimiser.zero_grad()\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "            return loss.detach().numpy().tolist()\n",
    "\n",
    "        def process_epoch() -> float:\n",
    "            return [process_batch(X, y) for X, y in data_loader][-1]\n",
    "\n",
    "        optimiser = torch.optim.SGD(self.parameters(), lr=0.05)\n",
    "        training_run = [process_epoch() for epoch in range(n_epochs)]\n",
    "        return training_run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "friendly-jacket",
   "metadata": {},
   "source": [
    "We now training the model using `optim`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "strange-welsh",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.513684630393982,\n",
       " 1.6031246185302734,\n",
       " 1.5727497339248657,\n",
       " 1.5829020738601685,\n",
       " 1.5794906616210938,\n",
       " 1.5806349515914917,\n",
       " 1.580250859260559,\n",
       " 1.5803797245025635,\n",
       " 1.5803368091583252,\n",
       " 1.5803511142730713,\n",
       " 1.5803461074829102,\n",
       " 1.5803478956222534,\n",
       " 1.5803468227386475,\n",
       " 1.5803474187850952,\n",
       " 1.5803474187850952]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg_pt = LinearRegressionPyTorch(1, 1)\n",
    "lin_reg_pt.fit(data_loader, n_epochs=15, learning_rate=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daily-grammar",
   "metadata": {},
   "source": [
    "Testing the model on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "scheduled-breathing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0649, grad_fn=<SqrtBackward>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse = torch.sqrt(torch.mean((lin_reg_pt.forward(test_data.X) - test_data.y) ** 2))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominant-representative",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
